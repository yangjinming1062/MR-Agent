from functools import wraps

import yaml

from defines import BAD_EXTENSIONS
from defines import CONSTANTS
from utils import logger


def _parse_code_suggestion(data):
    """
    å°†dictè½¬æ¢ä¸ºmarkdownæ ¼å¼ï¼ˆä¸“é—¨å¤„ç†ä»£ç å»ºè®®çš„ï¼‰ã€‚

    Args:
        data (dict): ä»£ç å»ºè®®

    Returns:
        str: markdownæ ¼å¼å­—ç¬¦ä¸²
    """
    markdown_text = f"\n\n### **ğŸ¤– {CONSTANTS.CODE_SUGGESTIONS}:**\n\n"
    for sub_key, sub_value in data.items():
        if sub_key in {CONSTANTS.EXISTING_CODE, CONSTANTS.IMPROVED_CODE}:
            markdown_text += f"\n  - **{sub_key}:**\n```\n{sub_value}\n\n```"
        else:
            markdown_text += f"\n  - **{sub_key}:** {sub_value}\n"
            markdown_text = markdown_text.rstrip("\n") + "   \n"  # works for gitlab and bitbucker

    markdown_text += "\n"
    return markdown_text


def convert_to_markdown(data):
    """
    å°†dictè½¬æ¢ä¸ºmarkdownæ ¼å¼ã€‚

    Args:
        data (dict): è½¬æ¢å‰çš„dictæ•°æ®

    Returns:
        str: markdownæ ¼å¼å­—ç¬¦ä¸²
    """
    markdown_text = ""

    emojis = {
        CONSTANTS.THEME: "ğŸ¯",
        CONSTANTS.SUMMARY: "ğŸ“",
        CONSTANTS.LABEL_OF_MR: "ğŸ“Œ",
        CONSTANTS.SCORE: "ğŸ…",
        CONSTANTS.TESTS: "ğŸ§ª",
        CONSTANTS.ERROR: "âŒ",
        CONSTANTS.FOCUSED: "âœ¨",
        CONSTANTS.SECURITY_CONCERNS: "ğŸ”’",
        CONSTANTS.SUGGESTION: "ğŸ’¡",
        CONSTANTS.REVIEW_ESTIMATED: "â±ï¸",
    }

    for key, value in data.items():
        if not value:
            continue
        if isinstance(value, dict):
            markdown_text += f"## {key}\n\n"
            markdown_text += convert_to_markdown(value)
        elif isinstance(value, list):
            emoji = emojis.get(key, "")
            if key != CONSTANTS.CODE_SUGGESTIONS:
                markdown_text += f"- {emoji} **{key}:**\n\n"
            for item in value:
                if key == CONSTANTS.CODE_SUGGESTIONS:
                    markdown_text += _parse_code_suggestion(item)
                else:
                    markdown_text += f"  - {item}\n"
        elif value != "n/a":
            emoji = emojis.get(key, "")
            markdown_text += f"- {emoji} **{key}:** {value}\n"
    return markdown_text


def _try_fix_yaml(response_text):
    """
    å°è¯•ä¿®å¤æ— æ³•åŠ è½½çš„yamlå­—ç¬¦ä¸²

    Args:
        response_text (str):

    Returns:
        dict
    """
    response_text_lines = response_text.split("\n")
    keys = [f"{CONSTANTS.SUGGESTION}:", f"{CONSTANTS.RELEVANT_FILE}:"]

    # first fallback - try to convert 'relevant line: ...' to relevant line: |-\n        ...'
    new_lines = []
    for i, row in enumerate(response_text_lines):
        for k in keys:
            if k in row and "|-" not in row:
                new_lines.append(row.replace(f"{k}", f"{k} |-\n        "))
                break
        else:
            new_lines.append(row)
    try:
        return yaml.safe_load("\n".join(new_lines))
    except:
        logger.info("Failed to parse AI prediction after adding |-\n")

    # second fallback - try to remove last lines
    data = {}
    for i in range(1, len(response_text_lines)):
        try:
            data = yaml.safe_load(
                "\n".join(response_text_lines[:-i]),
            )
            logger.info(f"Successfully parsed AI prediction after removing {i} lines")
            break
        except:
            pass
    return data


def load_yaml(response_text):
    """
    åŠ è½½yamlæ ¼å¼å­—ç¬¦ä¸²

    Args:
        response_text (str):

    Returns:
        dict
    """
    response_text = response_text.removeprefix("```yaml").rstrip("`")
    try:
        data = yaml.safe_load(response_text)
    except Exception as e:
        logger.error(f"Failed to parse AI prediction: {e}")
        data = _try_fix_yaml(response_text)
    return data


def clip_tokens(token_handler, text, max_tokens):
    """
    å°†å­—ç¬¦ä¸²ä¸­çš„ä»¤ç‰Œæ•°é‡è£å‰ªä¸ºæœ€å¤§ä»¤ç‰Œæ•°é‡(å¦‚æœè¶…å‡ºé™åˆ¶çš„è¯)ã€‚

    Args:
        token_handler (TokenHandler):
        text (str): å¾…ä¿®å»ºçš„å­—ç¬¦ä¸²ã€‚
        max_tokens (int): å­—ç¬¦ä¸²ä»¤ç‰Œä¸Šé™ã€‚

    Returns:
        str: ä¿®å‰ªåçš„å­—ç¬¦ä¸²ã€‚
    """
    if not text:
        return text

    try:
        if (num_input_tokens := token_handler.count_tokens(text)) <= max_tokens:
            return text
        chars_per_token = len(text) / num_input_tokens
        num_output_chars = int(chars_per_token * max_tokens)
        return text[:num_output_chars]
    except Exception as e:
        logger.warning(f"Failed to clip tokens: {e}")
        return text


def call_with_retry(function):
    """
    è£…é¥°å™¨: å¼‚å¸¸æ•è·ã€‚

    Returns:
        str | None:
    """

    @wraps(function)
    def wrapper(*args, **kwargs):
        for _ in range(3):
            try:
                return function(*args, **kwargs)
            except Exception as ex:
                logger.debug(ex)

    return wrapper


def is_valid_file(filename):
    """
    è¿‡æ»¤æ‰ä¸æ”¯æŒçš„æ–‡ä»¶

    Args:
        filename (str): æ–‡ä»¶å

    Returns:
        bool: æ˜¯å¦æœ‰åº
    """
    return filename.split(".")[-1] not in BAD_EXTENSIONS
